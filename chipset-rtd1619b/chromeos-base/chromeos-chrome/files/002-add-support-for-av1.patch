diff --git a/media/gpu/v4l2/legacy/v4l2_video_decode_accelerator.cc b/media/gpu/v4l2/legacy/v4l2_video_decode_accelerator.cc
index 8052b4d74223e..6f71306a9d7af 100644
--- a/media/gpu/v4l2/legacy/v4l2_video_decode_accelerator.cc
+++ b/media/gpu/v4l2/legacy/v4l2_video_decode_accelerator.cc
@@ -90,6 +90,8 @@ static const std::vector<uint32_t> kSupportedInputFourCCs = {
     V4L2_PIX_FMT_H264,
     V4L2_PIX_FMT_VP8,
     V4L2_PIX_FMT_VP9,
+    V4L2_PIX_FMT_HEVC,
+    V4L2_PIX_FMT_AV1,
 };
 
 // static
diff --git a/media/gpu/v4l2/v4l2_vda_helpers.cc b/media/gpu/v4l2/v4l2_vda_helpers.cc
index ee0dd6d892010..79617d6aace25 100644
--- a/media/gpu/v4l2/v4l2_vda_helpers.cc
+++ b/media/gpu/v4l2/v4l2_vda_helpers.cc
@@ -162,6 +162,9 @@ InputBufferFragmentSplitter::CreateFromProfile(
     case VideoCodec::kVP9:
       // VP8/VP9 don't need any frame splitting, use the default implementation.
       return std::make_unique<v4l2_vda_helpers::InputBufferFragmentSplitter>();
+    case VideoCodec::kAV1:
+      // Depends on downstream frame splitting, use the default implementation
+      return std::make_unique<v4l2_vda_helpers::InputBufferFragmentSplitter>();
     default:
       LOG(ERROR) << "Unhandled profile: " << profile;
       return nullptr;
diff --git a/media/gpu/v4l2/v4l2_video_decoder_backend_stateful.cc b/media/gpu/v4l2/v4l2_video_decoder_backend_stateful.cc
index 41778ce6be158..6ad8e3ea0c4be 100644
--- a/media/gpu/v4l2/v4l2_video_decoder_backend_stateful.cc
+++ b/media/gpu/v4l2/v4l2_video_decoder_backend_stateful.cc
@@ -758,6 +758,7 @@ bool V4L2StatefulVideoDecoderBackend::IsSupportedProfile(
 #endif  // BUILDFLAG(ENABLE_HEVC_PARSER_AND_HW_DECODER)
       V4L2_PIX_FMT_VP8,
       V4L2_PIX_FMT_VP9,
+      V4L2_PIX_FMT_AV1,
     };
     auto device = base::MakeRefCounted<V4L2Device>();
     VideoDecodeAccelerator::SupportedProfiles profiles =
